{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from zeep import Client, Settings\n",
    "import zeep\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.dates import DateFormatter\n",
    "import json as js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaName = 'WalnutGulch'\n",
    "#areaName = 'LittleRiver'\n",
    "\n",
    "match areaName:\n",
    "    case 'WalnutGulch':\n",
    "        path     = 62\n",
    "        frame    = 620\n",
    "    case 'LittleRiver':\n",
    "        path     = 47\n",
    "        frame    = 620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set some locations and variables\n",
    "workDir                      = '/scratch/rlohman/'+areaName+'/Path'+str(path)+'Frame'+str(frame)+'/'\n",
    "fgcovDir                     = workDir+'filtgcov/'\n",
    "NRCS_AWDB_SOAP_WSDL_URL      = \"https://wcc.sc.egov.usda.gov/awdbWebService/services?WSDL\"\n",
    "NRCS_AWDB_REST_DATA_ENDPOINT = \"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/data\"\n",
    "ELEMENT_CODES                = (\"SMS:*\")# Soil Moisture PERCENT\n",
    "DURATION                     = \"DAILY\"\n",
    "retNames                     = ['DSG','PMI','TSR']\n",
    "nret                         = len(retNames)\n",
    "maxdays                      = 7 #use closest in situ measurement to retrieval date, with max time difference = maxdays \n",
    "targerr                      = 6 #UBRMSE target range in percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get list of gcovs, ordered by date (will need to replace with ASF search by track/frame, when available)\n",
    "gcovs     = glob.glob(fgcovDir+'2*h5')\n",
    "dates     = np.array([datetime.datetime.strptime(x[-11:-3],'%Y%m%d') for x in gcovs])\n",
    "sortindex = np.argsort(dates)\n",
    "\n",
    "dates     = [dates[x] for x in sortindex]\n",
    "gcovs     = [gcovs[x] for x in sortindex]\n",
    "\n",
    "#Get Lat/Lon for searching through sparse network\n",
    "fo        = h5py.File(gcovs[0],'r')\n",
    "lat       = fo['latitude'][()]\n",
    "lon       = fo['longitude'][()]\n",
    "s0        = fo['Sigma0_hh_aggregated'][()] #just for plotting\n",
    "fo.close()\n",
    "s0dB      = 10*np.log10(s0)\n",
    "s01       = np.nanpercentile(s0dB,2,axis=None) #for color range below\n",
    "s02       = np.nanpercentile(s0dB,98,axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#API lets us search min/max long/lat\n",
    "minLongitude = np.min(lon)\n",
    "maxLongitude = np.max(lon)\n",
    "minLatitude  = np.min(lat)\n",
    "maxLatitude  = np.max(lat)\n",
    "#for plotting\n",
    "footprint    = np.array([[minLongitude, minLatitude],[minLongitude, maxLatitude],[maxLongitude, maxLatitude],[maxLongitude, minLatitude],[minLongitude, minLatitude]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings         = Settings(strict=False, xml_huge_tree=True)\n",
    "client           = Client(NRCS_AWDB_SOAP_WSDL_URL,settings=settings)\n",
    "station_triplets = client.service.getStations(elementCds='SMS',minLatitude=minLatitude,maxLatitude=maxLatitude,minLongitude=minLongitude,maxLongitude=maxLongitude, logicalAnd=True)\n",
    "\n",
    "data             = client.service.getStationMetadataMultiple(stationTriplets=station_triplets)\n",
    "df               = pd.DataFrame.from_records(zeep.helpers.serialize_object(data))\n",
    "ptlon            = df.longitude.to_numpy().astype('float')\n",
    "ptlat            = df.latitude.to_numpy().astype('float')\n",
    "\n",
    "print(str(len(station_triplets))+' stations in footprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get GCOV pixel for each in situ station within frame\n",
    "idx  = np.array([np.linalg.norm(x) for x in lon-ptlon]).argmin()\n",
    "idy  = np.array([np.linalg.norm(x) for x in lat-ptlat]).argmin()\n",
    "\n",
    "# Pull retrieval values from all gcovs\n",
    "retr = np.zeros([len(gcovs),nret])\n",
    "for i in range(len(gcovs)):\n",
    "    fo=h5py.File(gcovs[i],'r')\n",
    "    for j in range(nret):\n",
    "        retr[i,j] =fo['Algorithm/'+retNames[j]+'/Soil_moisture'][idy,idx]\n",
    "    fo.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2)\n",
    "\n",
    "# CONUS basemap.\n",
    "m = Basemap(projection='merc',llcrnrlat=24,urcrnrlat=49,llcrnrlon=-125,urcrnrlon=-66,lat_ts=35,resolution=None,ax=axes[0])\n",
    "m.shadedrelief()\n",
    "xpt,ypt=m(footprint[:,0],footprint[:,1])\n",
    "m.plot(xpt,ypt,'g')\n",
    "xpt,ypt=m(ptlon,ptlat)\n",
    "m.plot(xpt,ypt,'m^')\n",
    "\n",
    "#zoom in version\n",
    "m = Basemap(projection='merc',llcrnrlat=minLatitude-0.1,urcrnrlat=maxLatitude+0.1,llcrnrlon=minLongitude-0.1,urcrnrlon=maxLongitude+0.1,lat_ts=np.mean(footprint[:,1]),resolution='i',ax=axes[1])\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "xpt,ypt=m(footprint[:,0],footprint[:,1])\n",
    "m.plot(xpt,ypt,'g')\n",
    "m.pcolor(np.linspace(xpt[1],xpt[2],num=len(lon)+1),np.linspace(ypt[0],ypt[1],num=len(lat)+1),s0dB,vmin=s01,vmax=s02,cmap='gray',shading='flat')\n",
    "xpt,ypt=m(ptlon,ptlat)\n",
    "m.plot(xpt,ypt,'m^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_awdb_data_query_string(\n",
    "    station_triplet: str,\n",
    "    begin_date: str,\n",
    "    end_date: str,\n",
    "    elements: tuple[str, ...],\n",
    "    duration: str,\n",
    "):\n",
    "    \"\"\"Build querystring for the AWDB REST /data endpoint to get station data.\"\"\"\n",
    "    return \"&\".join(\n",
    "        [\n",
    "            f\"stationTriplets={station_triplet}\",\n",
    "            f\"beginDate={begin_date}\",\n",
    "            f\"endDate={end_date}\",\n",
    "            \"elements=SMS%3A%2A\",\n",
    "            f\"duration={duration}\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def _series_from_date_value_dicts(arr: list[dict]):\n",
    "    \"\"\"Utility to build a pandas Series from the {\"date\": ..., \"value\": ...} JSON records returned\n",
    "    by the AWDB REST Service data/ endpoint.\n",
    "    \"\"\"\n",
    "    dates, values = zip(*[(entry[\"date\"], entry[\"value\"]) for entry in arr])\n",
    "    return pd.Series(values, index=dates, dtype=\"float\")\n",
    "\n",
    "def get_data_for_station(station_triplet: str, begin_date: datetime.date, end_date: datetime.date) -> pd.DataFrame:\n",
    "    \"\"\"Returns data from NRCS AWDB for a station over given date range.\"\"\"\n",
    "    if type(station_triplet) is list:\n",
    "        if len(station_triplet) > 1 :\n",
    "            station_triplet=','.join(station_triplet)\n",
    "\n",
    "    url = (\n",
    "        NRCS_AWDB_REST_DATA_ENDPOINT\n",
    "        + \"?\"\n",
    "        + build_awdb_data_query_string(\n",
    "            station_triplet=station_triplet,\n",
    "            begin_date=begin_date.strftime(\"%Y-%m-%d\"),\n",
    "            end_date=end_date.strftime(\"%Y-%m-%d\"),\n",
    "            elements=ELEMENT_CODES,\n",
    "            duration=DURATION,\n",
    "        )\n",
    "    )\n",
    "    print(url)\n",
    "    session = requests.Session()\n",
    "    response = session.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        if len(response.json())>0:\n",
    "            data = {\n",
    "                entry[\"stationElement\"][\"elementCode\"]\n",
    "                + \"_\"\n",
    "                + entry[\"stationElement\"][\"durationName\"]: _series_from_date_value_dicts(entry[\"values\"])\n",
    "                for entry in response.json()[0][\"data\"]\n",
    "            }\n",
    "            df = pd.DataFrame(data)\n",
    "            df.index.name = \"date\"\n",
    "        else:\n",
    "            print('No data found')\n",
    "            df = pd.DataFrame()\n",
    "    else:\n",
    "        print('Error at site')\n",
    "        df = pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "begin_date         = dates[0]+timedelta(days=-7) #pull data for a slightly larger range, in case there isn't data on the exact gcov date\n",
    "end_date           = dates[-1]+timedelta(days=7)\n",
    "end_date           = datetime.datetime(2023,12,1)\n",
    "data_df            = get_data_for_station(station_triplets[0], begin_date, end_date)\n",
    "\n",
    "dfdates            = data_df.index.values\n",
    "dfdn               = np.array([datetime.datetime.strptime(x,'%Y-%m-%d') for x in dfdates])          #datetime values for in situd data\n",
    "dd                 = np.array([np.abs(x-dfdn) for x in dates]).astype('timedelta64[D]').astype(int) #delta time from gcov dates (matrix)\n",
    "ddmin              = np.min(dd,1)                                                                   #closest time for each gcov date\n",
    "indices            = np.argmin(dd, axis=1)                                                          #index of closest time\n",
    "bigGap             = np.argwhere(ddmin>=maxdays)                                                    #which gcov dates have no in situ date within maxdays\n",
    "insituDates        = dfdn[indices]                                                                  #dates of closest in situ data for each gcov\n",
    "insituData         = data_df['SMS_DAILY'][indices].values                                           #in situ data for each gcov date\n",
    "insituData[bigGap] = np.nan                                                                         #set values that are too many days away to NaN\n",
    "\n",
    "minval             = np.nanmin([np.nanmin(data_df['SMS_DAILY'].values),np.nanmin(retr*100,axis=None)])-2 #for plotting\n",
    "maxval             = np.nanmax([np.nanmax(data_df['SMS_DAILY'].values),np.nanmax(retr*100,axis=None)])+2\n",
    "\n",
    "res                = retr-np.transpose(np.tile(insituData/100,(3,1)))\n",
    "UBRMSE             = np.sqrt(np.nansum((res-np.nanmean(res,axis=0))**2,axis=0)/len(insituData))\n",
    "\n",
    "\n",
    "print(retNames, ' UBRMSE:', UBRMSE)\n",
    "print('Std Dev of res:',np.nanstd(res,ddof=1,axis=0)) #ddof=1 enforces /(n-1) instead of /n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myFmt    = DateFormatter(\"%Y%m\")\n",
    "labels    =retNames.copy()\n",
    "labels.insert(0,'insitu')\n",
    "fig, ax1 = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1[0].set_xlabel('date')\n",
    "ax1[0].set_ylabel('mv, %', color=color)\n",
    "ln1=ax1[0].plot(dfdn,data_df['SMS_DAILY'], '.',color=color)\n",
    "ax1[0].tick_params(axis='y', labelcolor=color)\n",
    "ax1[0].set_xticks([datetime.datetime(2022,1,1),datetime.datetime(2022,7,1),datetime.datetime(2023,1,1),datetime.datetime(2023,7,1)])\n",
    "ax1[0].xaxis.set_major_formatter(myFmt)\n",
    "ax1[0].set_ylim([minval,maxval])\n",
    "\n",
    "ax2 = ax1[0].twinx()             # instantiate a second Axes that shares the same x-axis\n",
    "ax2.set_ylabel('retrievals')  # we already handled the x-label with ax1\n",
    "ln2=ax2.plot(dates,retr*100,'.' )\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.set_ylim([minval,maxval])\n",
    "ax2.legend(ln1+ln2,labels)\n",
    "\n",
    "ax1[1].set_xlabel('date')\n",
    "ax1[1].set_ylabel('mv, %', color=color)\n",
    "ln1=ax1[1].plot(dfdn,data_df['SMS_DAILY'], '.',color=color)\n",
    "ax1[1].tick_params(axis='y', labelcolor=color)\n",
    "ax1[1].set_xticks([datetime.datetime(2022,1,1),datetime.datetime(2022,7,1),datetime.datetime(2023,1,1),datetime.datetime(2023,7,1)])\n",
    "ax1[1].xaxis.set_major_formatter(myFmt)\n",
    "ax1[1].set_ylim([minval,maxval])\n",
    "\n",
    "ax3 = ax1[1].twinx()             # instantiate a second Axes that shares the same x-axis\n",
    "ax3.set_ylabel('retrievals')  # we already handled the x-label with ax1\n",
    "ln2=ax3.plot(dates,(retr-np.nanmean(res,axis=0))*100,'.' )\n",
    "ax3.tick_params(axis='y')\n",
    "ax3.set_ylim([minval,maxval])\n",
    "ax3.legend(ln1+ln2,labels)\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color  = 'tab:red'\n",
    "labels =retNames.copy()\n",
    "labels.insert(0,'+/- '+str(targerr)+'%')\n",
    "labels.insert(0,'insitu')\n",
    "fig, ax1 = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax1[0].set_xlabel('date')\n",
    "ax1[0].set_ylabel('mv, %', color=color)\n",
    "ln1=ax1[0].plot(insituDates,insituData, '.-', color=color)\n",
    "ax1[0].tick_params(axis='y', labelcolor=color)\n",
    "ax1[0].set_xticks([datetime.datetime(2022,1,1),datetime.datetime(2022,7,1),datetime.datetime(2023,1,1),datetime.datetime(2023,7,1)])\n",
    "ax1[0].xaxis.set_major_formatter(myFmt)\n",
    "ax1[0].set_ylim([minval,maxval])\n",
    "\n",
    "ax2 = ax1[0].twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "ax2.set_ylabel('retrievals, %')  # we already handled the x-label with ax1\n",
    "ln2=ax2.plot(dates,retr*100 )\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.set_ylim([minval,maxval])\n",
    "ax2.legend(ln1+ln2,labels)\n",
    "\n",
    "\n",
    "ax1[1].set_xlabel('date')\n",
    "ax1[1].set_ylabel('mv, %', color=color)\n",
    "ln1=ax1[1].plot(insituDates,insituData, '.-', color=color)\n",
    "ln2=ax1[1].plot(insituDates,insituData-targerr, '--', color='lightgray')\n",
    "ax1[1].plot(insituDates,insituData+targerr, '--', color='lightgray')\n",
    "ax1[1].tick_params(axis='y', labelcolor=color)\n",
    "ax1[1].set_xticks([datetime.datetime(2022,1,1),datetime.datetime(2022,7,1),datetime.datetime(2023,1,1),datetime.datetime(2023,7,1)])\n",
    "ax1[1].xaxis.set_major_formatter(myFmt)\n",
    "ax1[1].set_ylim([minval,maxval])\n",
    "\n",
    "ax3 = ax1[1].twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "ax3.set_ylabel('retrievals, %')  # we already handled the x-label with ax1\n",
    "ln3=ax3.plot(dates,(retr-np.nanmean(res,axis=0))*100 )\n",
    "ax3.tick_params(axis='y')\n",
    "ax3.set_ylim([minval,maxval])\n",
    "ax3.legend(ln1+ln2+ln3,labels)\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isce3_src_cpu",
   "language": "python",
   "name": "isce3_src_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
