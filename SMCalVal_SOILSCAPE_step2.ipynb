{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: SOILSCAPE data\n",
    "\n",
    "### This notebook performs the following:\n",
    "- Reads csv file with info about the SOILSCAPE sites and NISAR track/frames relevant to each EASEGrid cell\n",
    "- For each NISAR track/frame\n",
    "    - Gets NISAR dates and retrievals \n",
    "    - Gets SOILSCAPE data for relevant dates\n",
    "    - Writes to csv file\n",
    "\n",
    "### Notes\n",
    "\n",
    "\n",
    "### Cite data as:\n",
    "- A. Melebari et al., \"CYGNSS SoilSCAPE Sites: Sensor Calibration and Data Analysis,\" IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium, Pasadena, CA, USA, 2023, pp. 4628-4630, doi: 10.1109/IGARSS52108.2023.10282411.\n",
    "- Use the digital object identifier provided in the id attribute when citing this data. See https://podaac.jpl.nasa.gov/CitingPODAAC ; \n",
    "- 10.5067/CSCAP-L1V10\n",
    "\n",
    "### SOILSCAPE contacts:\n",
    "- Amer Melebari, Ruzbeh Akbar, Erik Hodges, Darren McKague, Christopher S. Ruf, Agnelo Silva, Mahta Moghaddam\n",
    "- amelebar@usc.edu, rakbar@mit.edu, ehodges@usc.edu, dmckague@umich.edu, cruf@umich.edu, agnelors@gmail.com , mahta@usc.edu\n",
    "\n",
    "### More info at:\n",
    "-  https://soilscape.usc.edu/sites-and-data/\n",
    "\n",
    "### Necessary files\n",
    "- soilscape_site_nodeLocations.csv - generated by hand using info from the main SOILSCAPE site (name,node#,lon,lat)\n",
    "\n",
    "### Notes\n",
    "- csv link of form https://soilscape.usc.edu/?csv_download_moisture=1&csv_download_moisture_site_id=25&valid_only=1&start_date=2022-05-04&end_date=2022-05-20\n",
    "- fails above some unknown threshold, a month of data seems fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import glob\n",
    "\n",
    "from utilsCalVal import EASEconvert,readWalnutGulch\n",
    "import setParams as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilscapePath      = p.soilscapePath\n",
    "modNames           = p.modNames\n",
    "# Use which depth sensors?\n",
    "allDepths          = [5,10,20,30]\n",
    "targetDepth        = 0 #index of which depth to use\n",
    "startDate          = p.startDate\n",
    "endDate            = p.endDate\n",
    "\n",
    "#Step1 output: easegrid cells and info\n",
    "tmpOut             = soilscapePath+'temp/' #for temporary unzipped files\n",
    "soilscapeSitesPath = p.soilscapeSitesPath\n",
    "\n",
    "#api info: root:\n",
    "soilscapeAPI        = 'https://soilscape.usc.edu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check files and make initial directory\n",
    "Path(tmpOut).mkdir(parents=True, exist_ok=True) #make soilscape directory if does not already exist\n",
    "if not(os.path.isdir(soilscapePath)):\n",
    "    print('Error: Must run Step1 first')\n",
    "if not(os.path.isfile(soilscapeSitesPath)):\n",
    "    print('Error: need metadata file '+soilscapeSitesPath+' made in Step1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitesDF      = pd.read_csv(soilscapeSitesPath,index_col=None)  #sorted by EASEGRID cells, not individual SOILSCAPE sites\n",
    "nsites       = len(sitesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each site, for each track/frame, get SAR retrievals and metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(nsites):\n",
    "    ezr        = sitesDF['EASEGridRowIndex'][i]\n",
    "    ezc        = sitesDF['EASEGridColIndex'][i]\n",
    "    framecount = sitesDF['framecount'][i]\n",
    "    tracks=sitesDF['tracks'][i][1:-1] #take off [ ]\n",
    "    tracks=np.fromstring(tracks,dtype='int',sep=',')\n",
    "    \n",
    "    frames=sitesDF['frames'][i][1:-1] #take off [ ]\n",
    "    frames=np.fromstring(frames,dtype='int',sep=',')\n",
    "    \n",
    "    for j in range(framecount):\n",
    "        #if Luckyhills or Kendall, read in Walnut Gulch area A\n",
    "        if ezr<17310 and ezr>17303:\n",
    "            dates,retr,rete,retq = readWalnutGulch(ezr,ezc)\n",
    "        \n",
    "            trackDF=pd.DataFrame(data=dates,columns=['datetimeUTC'])  \n",
    "            for k in range(len(modNames)):\n",
    "                trackDF[modNames[k]]          = retr[:,k]\n",
    "                trackDF[modNames[k]+'stddev'] = rete[:,k]\n",
    "                trackDF[modNames[k]+'Qflag']  = retq[:,k]\n",
    "\n",
    "            for k in range(len(dates)):\n",
    "                d1=datetime.datetime.strftime(dates[k]+datetime.timedelta(days=-1),'%Y-%m-%d')\n",
    "                d2=datetime.datetime.strftime(dates[k]+datetime.timedelta(days=2),'%Y-%m-%d')\n",
    "                apiCall=soilscapeAPI+'?csv_download_moisture=1&csv_download_moisture_site_id='+str(sitesDF['siteID'][i])+'&valid_only=1&start_date='+d1+'&end_date='+d2\n",
    "                \n",
    "                print(apiCall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiCall='https://soilscape.usc.edu/?csv_download_moisture=1&csv_download_moisture_site_id=15&valid_only=1&start_date=2022-07-16&end_date=2022-07-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with urlopen(apiCall) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(tmpOut)\n",
    "\n",
    "\n",
    "csvfile  = np.array(glob.glob(tmpOut+'*.csv'))\n",
    "\n",
    "newDF      = pd.read_csv(csvfile[0],index_col=None)  #sorted by EASEGRID cells, not individual SOILSCAPE sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/SMCalValdir/SOILSCAPE/temp/jr-3_soil_20220504_20220520.csv\n"
     ]
    }
   ],
   "source": [
    "csvfile  = np.array(glob.glob(tmpOut+'*.csv'))\n",
    "print(csvfile[0])\n",
    "newDF      = pd.read_csv(csvfile[0],index_col=None)  #sorted by EASEGRID cells, not individual SOILSCAPE sites\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5   \n",
      "0           NaN         NaN         NaN         NaN         NaN         NaN  \\\n",
      "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2           NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "168         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "169         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "170         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "171         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "172         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "     Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 30   \n",
      "0           NaN         NaN         NaN         NaN  ...          NaN  \\\n",
      "1           NaN         NaN         NaN         NaN  ...          NaN   \n",
      "2           NaN         NaN         NaN         NaN  ...          NaN   \n",
      "3           NaN         NaN         NaN         NaN  ...          NaN   \n",
      "4           NaN         NaN         NaN         NaN  ...          NaN   \n",
      "..          ...         ...         ...         ...  ...          ...   \n",
      "168         NaN         NaN         NaN         NaN  ...          NaN   \n",
      "169         NaN         NaN         NaN         NaN  ...          NaN   \n",
      "170         NaN         NaN         NaN         NaN  ...          NaN   \n",
      "171         NaN         NaN         NaN         NaN  ...          NaN   \n",
      "172         NaN         NaN         NaN         NaN  ...          NaN   \n",
      "\n",
      "     Unnamed: 31  Unnamed: 32  Unnamed: 33  Unnamed: 34  Unnamed: 35   \n",
      "0            NaN          NaN          NaN          NaN          NaN  \\\n",
      "1            NaN          NaN          NaN          NaN          NaN   \n",
      "2            NaN          NaN          NaN          NaN          NaN   \n",
      "3            NaN          NaN          NaN          NaN          NaN   \n",
      "4            NaN          NaN          NaN          NaN          NaN   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "168          NaN          NaN          NaN          NaN          NaN   \n",
      "169          NaN          NaN          NaN          NaN          NaN   \n",
      "170          NaN          NaN          NaN          NaN          NaN   \n",
      "171          NaN          NaN          NaN          NaN          NaN   \n",
      "172          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "     Unnamed: 36  Unnamed: 37  20220716.021708  1502  \n",
      "0            NaN          NaN     2.022072e+07  1503  \n",
      "1            NaN          NaN     2.022072e+07  1501  \n",
      "2            NaN          NaN     2.022072e+07  1502  \n",
      "3            NaN          NaN     2.022072e+07  1503  \n",
      "4            NaN          NaN     2.022072e+07  1504  \n",
      "..           ...          ...              ...   ...  \n",
      "168          NaN          NaN     2.022072e+07  1504  \n",
      "169          NaN          NaN     2.022072e+07  1501  \n",
      "170          NaN          NaN     2.022072e+07  1502  \n",
      "171          NaN          NaN     2.022072e+07  1503  \n",
      "172          NaN          NaN     2.022072e+07  1504  \n",
      "\n",
      "[173 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(newDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isce3_src_cpu",
   "language": "python",
   "name": "isce3_src_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
